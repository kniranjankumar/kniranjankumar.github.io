<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>K. Niranjan Kumar</title>

  <meta name="author" content="K. Niranjan Kumar">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¤–</text></svg>">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    K. Niranjan Kumar
                  </p>
                  <p>I am a PhD candidate at Georgia Institute of Technology working with <a
                        href="https://www.cc.gatech.edu/~sha9/" target="blank">Sehoon Ha</a> and <a
                        href="http://www.irfanessa.gatech.edu/" target="blank">Irfan Essa. </a>
                    My research is in the union of
                  <h3 style="text-align: center;">Robot learning + Legged robots + Interactive perception</h3>
                  <p>I am in the job market for post-doc and industry research roles in robotics. Please reach out to me
                    if you have any opportunities.</p>
                  <p style="text-align:center">
                    <a href="mailto:niranjankumar@gatech.edu">Email</a> &nbsp;/&nbsp;
                    <a href="data/KNiranjan_Kumar_resume.pdf">CV</a> &nbsp;/&nbsp;
                    <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                    <a href="https://scholar.google.com/citations?user=UD7d2NEAAAAJ&hl=en">Google Scholar</a>
                    &nbsp;/&nbsp;
                    <a href="https://twitter.com/kniranjankumar0">Twitter</a>
                    <!-- <a href="https://github.com/jonbarron/">Github</a> -->
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="img/prof_pic.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="img/prof_pic.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    My current research focus involves creating learning-based policies that enable high-DOF robots to
                    exhibit natural fluid behaviors, all while reducing the reliance on intricate reward engineering.
                    To this end, my ongoing work involves using Large Language Models (LLMs) for iterative, human-guided
                    refinement for learned control policies.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>


              <tr onmouseout="bumblebee_stop()" onmouseover="bumblebee_start()" bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='bumblebee_image'>
                      <video style="width: 160px; height: 160px; object-fit: cover; object-position: 0% 0%;" muted
                        autoplay loop>
                        <source src="img/words_into_action/hopping.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <img src='img/words_into_action/hop.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function bumblebee_start() {
                      document.getElementById('bumblebee_image').style.opacity = "1";
                    }

                    function bumblebee_stop() {
                      document.getElementById('bumblebee_image').style.opacity = "0";
                    }
                    zipnerf_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="http://www.kniranjankumar.com/words_into_action">
                    <span class="papertitle">Words into Action: Learning Diverse Humanoid Robot Behaviors using Language
                      Guided Iterative Motion Refinement</span>
                  </a>
                  <br>
                  <strong>K. Niranjan Kumar</strong>,
                  <a href="https://www.irfanessa.gatech.edu/">Irfan Essa</a>,
                  <a href="https://faculty.cc.gatech.edu/~sha9/">Sehoon Ha</a>

                  <br>
                  <em>LangRob workshop CoRL</em>, 2023
                  <br>
                  <a href="http://www.kniranjankumar.com/words_into_action">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2310.06226">arXiv</a>
                  <p></p>
                  <p>
                    Learning rich humanoid behaviors from human language instructions.
                  </p>
                </td>
              </tr>
              <tr onmouseout="bayrn_stop()" onmouseover="bayrn_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='bayrn_image'>
                      <video style="width: 160px; height: 160px; object-fit: cover; object-position: 60% 0%;" muted
                        autoplay loop>
                        <source src="img/bayrn/bayrn_policy.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <img src='img/bayrn/pushing_bayrn.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function bayrn_start() {
                      document.getElementById('bayrn_image').style.opacity = "1";
                    }

                    function bayrn_stop() {
                      document.getElementById('bayrn_image').style.opacity = "0";
                    }
                    zipnerf_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="http://www.kniranjankumar.com/">
                    <span class="papertitle">BayRnTune: Adaptive Bayesian Domain Randomization via Strategic
                      Fine-tuning</span>
                  </a>
                  <br>
                  <a href="https://www.linkedin.com/in/tianlehuang/">Tianle Huang</a>
                  <a href="https://www.linkedin.com/in/nitish-sontakke-3ab521231">Nitish Sontakke</a>
                  <strong>K. Niranjan Kumar</strong>,
                  <a href="https://www.irfanessa.gatech.edu/">Irfan Essa</a>,
                  <a href="https://faculty.cc.gatech.edu/~sha9/">Sehoon Ha</a>
                  <a href="https://stefanosnikolaidis.net/">Stefanos Nikolaidis</a>
                  <a href="https://samueli.ucla.edu/people/dennis-hong/">Dennis W Hong</a>

                  <br>
                  <em>Under Review</em>, 2023
                  <br>
                  <a href="http://arxiv.org/abs/2310.10606">arXiv</a>
                  <p></p>
                  <p>
                    Tune simulation parameters to efficiently transfer to target environment.
                  </p>
                </td>
              </tr>
              <tr onmouseout="ccrl_stop()" onmouseover="ccrl_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='ccrl_image'>
                      <video style="width: 160px; height: 160px; object-fit: cover; object-position: 60% 0%;" muted
                        autoplay loop>
                        <source src="img/ccrl/door_open.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <img src='img/ccrl/door_open.png' width="160" height="160">
                  </div>
                  <script type="text/javascript">
                    function ccrl_start() {
                      document.getElementById('ccrl_image').style.opacity = "1";
                    }

                    function ccrl_stop() {
                      document.getElementById('ccrl_image').style.opacity = "0";
                    }
                    zipnerf_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="http://www.kniranjankumar.com/ccrl">
                    <span class="papertitle">Cascaded Compositional Residual Learning for Complex Interactive
                      Behaviors</span>
                  </a>
                  <br>
                  <strong>K. Niranjan Kumar</strong>,
                  <a href="https://www.irfanessa.gatech.edu/">Irfan Essa</a>,
                  <a href="https://faculty.cc.gatech.edu/~sha9/">Sehoon Ha</a>

                  <br>
                  <em>Robotics and Automation Letters</em>, 2023
                  <br>
                  <a href="http://www.kniranjankumar.com/ccrl">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2212.08954">arXiv</a>
                  /
                  <a href="https://www.youtube.com/watch?v=8eyG79B0uP8">video</a>
                  <p></p>
                  <p>
                    Cascaded Compositional Residual Learning (CCRL), which learns composite skills by recursively
                    leveraging a library of previously learned control policies.
                  </p>
                </td>
              </tr>



              <tr onmouseout="clutter_stop()" onmouseover="clutter_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='clutter_image'>
                      <video style="width: 160px; height: 160px; object-fit: cover; object-position: 60% 0%;" muted
                        autoplay loop>
                        <source src="img/clutter/scene-graph.mov" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <img src='img/clutter/real_clutter.jpg' width="160">
                  </div>
                  <script type="text/javascript">
                    function clutter_start() {
                      document.getElementById('clutter_image').style.opacity = "1";
                    }

                    function clutter_stop() {
                      document.getElementById('clutter_image').style.opacity = "0";
                    }
                    zipnerf_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="projects/5_clutr/">
                    <span class="papertitle">Graph-based Cluttered Scene Generation and Interactive Exploration using
                      Deep Reinforcement Learning</span>
                  </a>
                  <br>
                  <strong>K. Niranjan Kumar</strong>,
                  <a href="https://www.irfanessa.gatech.edu/">Irfan Essa</a>,
                  <a href="https://faculty.cc.gatech.edu/~sha9/">Sehoon Ha</a>

                  <br>
                  <em>ICRA</em>, 2022
                  <br>
                  <a href="http://arxiv.org/abs/2109.10460">arXiv</a>
                  /
                  <a href="https://www.youtube.com/watch?v=T2Jo7wwaXss">video</a>
                  <p></p>
                  <p>
                    Finding hidden objects in structured cluttered environments using deep reinforcement learning.
                  </p>
                </td>
              </tr>


              <tr onmouseout="mass_stop()" onmouseover="mass_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='mass_prediction'>
                      <video style="width: 160px; height: 160px; object-fit: cover; object-position: 60% 0%;" muted
                        autoplay loop>
                        <source src="img/mass_prediction/mass_prediction.mov" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <img src='img/mass_prediction/timelapse.jpg' width="160">
                  </div>
                  <script type="text/javascript">
                    function mass_start() {
                      document.getElementById('mass_prediction').style.opacity = "1";
                    }

                    function mass_stop() {
                      document.getElementById('mass_prediction').style.opacity = "0";
                    }
                    zipnerf_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="http://arxiv.org/abs/1907.03964">
                    <span class="papertitle">Estimating Mass Distribution of Articulated Objects using Non-prehensile
                      Manipulation</span>
                  </a>
                  <br>
                  <strong>K. Niranjan Kumar</strong>,
                  <a href="https://www.irfanessa.gatech.edu/">Irfan Essa</a>,
                  <a href="https://faculty.cc.gatech.edu/~sha9/">Sehoon Ha</a>,
                  <a href="https://tml.stanford.edu/people/karen-liu">Karen Liu</a>

                  <br>
                  <em>Object Representations for Learning and Reasoning Workshop NeurIPS</em>, 2020
                  <br>
                  <a href="http://arxiv.org/abs/1907.03964">arXiv</a>
                  /
                  <a href="https://www.youtube.com/watch?v=o3zBdVWvWZw">video</a>
                  <p></p>
                  <p>
                    Learning interaction policies to estimate mass distribution of articulated objects in minimal steps.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <h2>Projects</h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='img/Smoke-output.gif' width="160" height="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="projects/motion_textures.html">
                    <span class="papertitle">Motion textures from static images</span>
                  </a>
                  <br>
                  <p>
                    Built an algorithm that converts an image into an infinitely looping video using a neural network
                    and user input.
                  </p>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='img/hand_move.gif' width="160" height="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="projects/hand_manipulation.html">
                    <span class="papertitle">Realistic video generation of hand-object interactions</span>
                  </a>
                  <br>
                  <p>
                    We generate realistic hand manipulations of object by using a Generative Adversarial Network by
                    conditioning on the hand and finger pose. We adopt an encoder-decoder architecture where we input a
                    rough rendering of the skeletal pose and get a realistic rendering of a hand as the output. We
                    generate datasets with simulated and real human arms at different poses and use it to train our
                    model. Given an hand pose and object pose we showcase a pipeline to generate an image conditioned on
                    the poses.
                  </p>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='img/eye_dropper_side.png' width="160" height="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="projects/eye_dropper.html">
                    <span class="papertitle">Automatic eye-dropper</span>
                  </a>
                  <br>
                  <p>
                    Design an automated eye-dropper that detects the patients eye, adminsters the eye drop and registers
                    if the adminstration was successful using CV (eye-tracking, blink detection, drop tracking).
                  </p>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='img/tele-robot.jpg' width="160" height="160"
                      style="object-fit: cover; object-position: 30% 0%;">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="img/Tele-robot.mp4">
                    <span class="papertitle">Tele-operated mobile robot</span>
                  </a>
                  <br>
                  <p>
                    Built a controller for tele-operated mobile robot that can be controlled using a computer keyboard.
                  </p>
                </td>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <h2>Service</h2>
                  <br>

                  Web Chair, <a href="https://www.corl2023.org">CoRL 2023</a><br>
                  Reviewer for <a href="https://www.ieee-ras.org/publications/t-ro">TRO</a>, <a
                    href="https://dl.acm.org/journal/thri">THRI</a>, <a href="https://ieee-iros.org/">IROS</a>, <a
                    href="https://www.ieee-ras.org/publications/ra-l">RAL</a>
                </td>
              </tr>
              <tr>
                <td>
                  <h2>Teaching</h2>
                  <br>

                  GTA for <a href="https://omscs.gatech.edu/cs-6475-computational-photography">CS6475 Computational Photography</a><br>
                </td>
              </tr>
              <tr>
                <td>
                  <h2>Mentoring Experience</h2>
                  <br>
                  I have had the pleasure of working with the following students over the years:<br>
                  <br>
                  <a href="https://www.linkedin.com/in/alexkimt/">Alex Kim</a><br>
                  <a href="https://www.linkedin.com/in/hrishikesh-kale-02b338140/">Hrishikesh Kale</a><br>
                  <a href="https://www.linkedin.com/in/xingfang-yuan-16437a220/">Xingfang Yuan</a><br>
                  Mili Das<br>
                </td>
              </tr>
            </tbody>
          </table>



          <!-- Footer -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    Template borrowed from <a href="https://github.com/jonbarron/jonbarron_website">here</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>